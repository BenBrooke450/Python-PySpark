


# PySpark — Count Distinct Examples

In **PySpark**, you can use `distinct().count()` or the SQL function `countDistinct()` to get the **distinct count** of rows or columns.

- `distinct()` eliminates duplicate records (matching all columns of a row).  
- `count()` returns the number of records in a DataFrame.  
  ➜ By chaining them (`distinct().count()`), you can get the distinct count.  

---

## Create SparkSession and Prepare Data

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
         .appName('SparkByExamples.com') \
         .getOrCreate()

data = [
    ("James", "Sales", 3000),
    ("Michael", "Sales", 4600),
    ("Robert", "Sales", 4100),
    ("Maria", "Finance", 3000),
    ("James", "Sales", 3000),
    ("Scott", "Finance", 3300),
    ("Jen", "Finance", 3900),
    ("Jeff", "Marketing", 3000),
    ("Kumar", "Marketing", 2000),
    ("Saif", "Sales", 4100)
]
columns = ["Name", "Dept", "Salary"]

df = spark.createDataFrame(data=data, schema=columns)
df.show()
````

### Output

```
+-------+---------+------+
|   Name|     Dept|Salary|
+-------+---------+------+
|  James|    Sales|  3000|
|Michael|    Sales|  4600|
| Robert|    Sales|  4100|
|  Maria|  Finance|  3000|
|  James|    Sales|  3000|
|  Scott|  Finance|  3300|
|    Jen|  Finance|  3900|
|   Jeff|Marketing|  3000|
|  Kumar|Marketing|  2000|
|   Saif|    Sales|  4100|
+-------+---------+------+
```

---

<br><br><br><br>

## Using `distinct()` and `count()`

The DataFrame has 10 rows, and one row is a complete duplicate.
Running `distinct().count()` removes duplicates and counts the remaining unique rows.

```python
# Applying distinct() and count()
df1 = df.distinct()
print(df1.count())   # Output: 9
df1.show()
```

### Output

```
9
+-------+---------+------+
|   Name|     Dept|Salary|
+-------+---------+------+
|Michael|    Sales|  4600|
|  James|    Sales|  3000|
| Robert|    Sales|  4100|
|  Scott|  Finance|  3300|
|  Maria|  Finance|  3000|
|    Jen|  Finance|  3900|
|  Kumar|Marketing|  2000|
|   Jeff|Marketing|  3000|
|   Saif|    Sales|  4100|
+-------+---------+------+
```

---

### Distinct on a Single Column

```python
# Apply distinct() and count() on a single column
df2 = df.select("Name").distinct()
print(df2.count())   # Output: 9
df2.show()
```

```
+-------+
|   Name|
+-------+
|  James|
|Michael|
| Robert|
|  Scott|
|  Maria|
|    Jen|
|  Kumar|
|   Saif|
|   Jeff|
+-------+
```

---

### Distinct on Multiple Columns

```python
# Applying distinct(), count() on multiple columns
df3 = df.select("Name", "Dept").distinct().count()
print(df3)
```

**Output**

```
9
```

<br><br><br><br>

## Using `countDistinct()` SQL Function

`distinct()` returns a DataFrame with duplicates removed.
If you want to **count distinct values** across *selected columns*, use `countDistinct()` from `pyspark.sql.functions`.

```python
from pyspark.sql.functions import countDistinct

df2 = df.select(countDistinct("Dept", "Salary"))
df2.show()
```

### Output

```
+----------------------------------+
|count(DISTINCT Dept, Salary)|
+----------------------------------+
|8                                 |
+----------------------------------+
```

Since `countDistinct()` returns a **Column** type, you must collect it to extract the numeric value.

```python
# Applying collect() after countDistinct()
print("Distinct Count of Department & Salary: " + str(df2.collect()[0][0]))
```

**Output**

```
Distinct Count of Department & Salary: 8
```


**Summary**

| Method                                        | Description                                      |
| --------------------------------------------- | ------------------------------------------------ |
| `distinct().count()`                          | Counts distinct rows in entire DataFrame         |
| `select("col").distinct().count()`            | Counts unique values in a column                 |
| `countDistinct("col1", "col2")`               | Counts distinct combinations of multiple columns |
| `spark.sql("SELECT COUNT(DISTINCT col) ...")` | SQL equivalent                                   |

<br><br><br><br>

# Example 1

```python
# Group and count directly
barchart_gender = df.groupBy("Sex").count()

# Collect results
data = barchart_gender.collect()

print(data)
#[Row(Sex='female', count=152), Row(Sex='male', count=266)]
```